                News Article Classification (Real/fake)

ðŸ”¹ Introduction
In todayâ€™s digital era, the widespread use of online platforms and social media has led to an exponential growth in information sharing. While this has made news more accessible, it has also created a serious challenge â€” the rapid spread of fake news. Misinformation can influence public opinion, create panic, and mislead people, making fake news detection an important research area.
This project aims to build a machine learning-based classification system that can automatically distinguish between real and fake news articles. By applying Natural Language Processing (NLP) techniques such as text preprocessing, feature extraction using TF-IDF, and machine learning algorithms like Logistic Regression and NaÃ¯ve Bayes, the system provides a reliable way to identify misinformation and support trustworthy news consumption.

Abstract 
The rise of online news platforms and social media has increased the risk of spreading false or misleading information, commonly known as fake news. This project focuses on developing a machine learning model that classifies news articles as either Real or Fake. The dataset used contains labeled articles, which were preprocessed by removing stopwords, applying lemmatization, and cleaning text. Features were extracted using the TF-IDF Vectorizer, and two models, Logistic Regression and Multinomial NaÃ¯ve Bayes, were trained and evaluated. The results show that Logistic Regression achieved higher accuracy compared to NaÃ¯ve Bayes, proving its effectiveness in fake news detection. This work demonstrates how Natural Language Processing (NLP) combined with machine learning can help combat misinformation.

Tools Used
Python â€“ Programming language used for implementation.
Pandas & NumPy â€“ For data handling, analysis, and numerical operations.
NLTK (Natural Language Toolkit) â€“ For text preprocessing such as stopword removal and lemmatization.
Scikit-learn â€“ For machine learning model training, evaluation, and metrics.
TF-IDF Vectorizer â€“ For converting textual data into numerical feature vectors.
Matplotlib & Seaborn â€“ For visualization of performance metrics and confusion matrix.

Steps Involved in Building the Project
Data Collection
      A labeled dataset containing Real and Fake news articles was used.
Data Preprocessing
   Removed special characters, punctuation, and numbers.
  Converted text to lowercase for consistency.
   Removed stopwords (common words like is, the, and).
   Applied lemmatization to reduce words to their root form.
Feature Extraction
 Used TF-IDF Vectorizer to transform text into numerical vectors that represent word   importance.
Model Training
 Trained two machine learning models:
Logistic Regression
Multinomial NaÃ¯ve Bayes
1.	Model Evaluation
Evaluated models using Accuracy, F1-score, Classification Report, and Confusion Matrix.
Logistic Regression achieved better performance compared to NaÃ¯ve Bayes.
2.	Result Analysis
Visualized confusion matrix and compared evaluation metrics.
Logistic Regression provided higher precision and recall.

Conclusion 
The Fake News Classification project successfully demonstrates the application of Natural Language Processing (NLP) and Machine Learning techniques in solving real-world problems. By applying preprocessing, feature extraction using TF-IDF, and training models such as Logistic Regression and NaÃ¯ve Bayes, the system effectively classifies news articles as Real or Fake. Among the two models, Logistic Regression achieved higher accuracy and reliability. This project highlights the potential of machine learning in combating misinformation and can be further enhanced by using advanced deep learning techniques for greater accuracy and scalability.


